{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20a71c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "file_path = \"/home/xuxin/allCode/bxi_ros2_example/observations/observation@2025-08-06_14-21-18.csv\"\n",
    "\n",
    "freq=100\n",
    "df=pd.read_csv(file_path, header=None)\n",
    "\n",
    "timestamp_column = df.values[:, 0]\n",
    "obs = df.values[:, 1:1+33]\n",
    "obs_history = df.values[:,34:34+47*66]\n",
    "action = df.values[:, 34+47*66:34+47*66+12]\n",
    "\n",
    "commands = obs[:, 0:3]\n",
    "dof_pos = obs[:, 3:15]\n",
    "dof_vel = obs[:, 15:27]\n",
    "obs_base_ang_vel = obs[:, 27:30]\n",
    "obs_euler_angle = obs[:, 30:33]\n",
    "\n",
    "time_length = timestamp_column.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25de66d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from humanoid_walk import humanoid_walk_onnx_Agent\n",
    "import numpy as np\n",
    "\n",
    "a=humanoid_walk_onnx_Agent(\"/home/xuxin/allCode/bxi_ros2_example/src/bxi_example_py_ankle/policy/model.onnx\")\n",
    "a.reset()\n",
    "np.set_printoptions(formatter={'float': '{:.2f}'.format})\n",
    "\n",
    "# 直接验证从obs_history推理是否一致\n",
    "for i in range(time_length):\n",
    "    obs_input = obs_history[i]\n",
    "    obs_input = obs_input[None,:].astype(np.float32)\n",
    "    input_feed = {\"input\": obs_input}\n",
    "\n",
    "    actions_2 = np.squeeze(a.onnx_session.run([\"output\"], input_feed))\n",
    "    actions_2 = np.clip(actions_2, -a.clip_action, a.clip_action)\n",
    "\n",
    "    if not np.allclose(action[i], actions_2, atol=0.01):\n",
    "        print(i)\n",
    "        print(action[i])\n",
    "        print(actions_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d006b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=humanoid_walk_onnx_Agent(\"/home/xuxin/allCode/bxi_ros2_example/src/bxi_example_py_ankle/policy/model.onnx\")\n",
    "a.reset()\n",
    "np.set_printoptions(formatter={'float': '{:.2f}'.format})\n",
    "\n",
    "for i in range(time_length):\n",
    "    obs_group={\n",
    "        \"dof_pos\":dof_pos[i],\n",
    "        \"dof_vel\":dof_vel[i],\n",
    "        \"angular_velocity\":obs_base_ang_vel[i],\n",
    "        \"euler_angle\":obs_euler_angle[i],\n",
    "        \"commands\":commands[i],\n",
    "    }\n",
    "    dof_target_2 = a.inference(obs_group)\n",
    "    actions_2 = a.last_actions\n",
    "    prop_obs_history = a.prop_obs_history.transpose().flatten() \n",
    "\n",
    "    # 验证obs_history构建是否一致\n",
    "    if not np.allclose(obs_history[i], prop_obs_history, atol=0.0001):\n",
    "        print(\"obs_history different\",i)\n",
    "        print(obs_history[i].reshape(66,47)[-1,:])\n",
    "        print(prop_obs_history.reshape(66,47)[-1,:])\n",
    "\n",
    "    # 验证action是否一致\n",
    "    if not np.allclose(action[i], actions_2, atol=0.0001):\n",
    "        print(\"action different\",i)\n",
    "        print(action[i])\n",
    "        print(actions_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3fad0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "model_path = \"/home/xuxin/allCode/bxi_ros2_example/src/bxi_example_py_ankle/policy/model.onnx\"\n",
    "\n",
    "providers = [\n",
    "    'CUDAExecutionProvider',  # 优先使用GPU\n",
    "    'CPUExecutionProvider'    # 回退到CPU\n",
    "] if ort.get_device() == 'GPU' else ['CPUExecutionProvider']\n",
    "\n",
    "# 启用线程优化配置\n",
    "options = ort.SessionOptions()\n",
    "options.intra_op_num_threads = 4  # 设置计算线程数\n",
    "options.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL\n",
    "\n",
    "# 创建推理会话\n",
    "session = ort.InferenceSession(\n",
    "    model_path,\n",
    "    providers=providers,\n",
    "    sess_options=options\n",
    ")\n",
    "\n",
    "# 预存输入输出信息\n",
    "input_info = session.get_inputs()[0]\n",
    "output_info = session.get_outputs()[0]\n",
    "\n",
    "# 预分配输入内存（可选，适合固定输入尺寸）\n",
    "input_buffer = np.zeros(\n",
    "    input_info.shape,\n",
    "    dtype=np.float32)\n",
    "\n",
    "def inference_step(obs_data):\n",
    "    # 使用预分配内存（如果适用）\n",
    "    np.copyto(input_buffer, obs_data)  # 比直接赋值更安全\n",
    "    \n",
    "    # 极简推理（比原版快5-15%）\n",
    "    return session.run(\n",
    "        [output_info.name], \n",
    "        {input_info.name: input_buffer}\n",
    "    )[0][0]  # 直接获取第一个输出的第一个样本\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6547487",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a=humanoid_walk_onnx_Agent(\"/home/xuxin/allCode/bxi_ros2_example/src/bxi_example_py_ankle/policy/model.onnx\")\n",
    "a.reset()\n",
    "np.set_printoptions(formatter={'float': '{:.2f}'.format})\n",
    "\n",
    "for i in range(time_length):\n",
    "    obs_group={\n",
    "        \"dof_pos\":dof_pos[i],\n",
    "        \"dof_vel\":dof_vel[i],\n",
    "        \"angular_velocity\":obs_base_ang_vel[i],\n",
    "        \"euler_angle\":obs_euler_angle[i],\n",
    "        \"commands\":commands[i],\n",
    "    }\n",
    "    dof_target_2 = a.inference(obs_group)\n",
    "    actions_2 = a.last_actions\n",
    "    prop_obs_history = a.prop_obs_history.transpose().flatten() \n",
    "\n",
    "    # 验证obs_history构建是否一致\n",
    "    if not np.allclose(obs_history[i], prop_obs_history, atol=0.0001):\n",
    "        print(\"obs_history different\",i)\n",
    "        print(obs_history[i].reshape(66,47)[-1,:])\n",
    "        print(prop_obs_history.reshape(66,47)[-1,:])\n",
    "\n",
    "    # 验证action是否一致\n",
    "    if not np.allclose(action[i], actions_2, atol=0.0001):\n",
    "        print(\"action different\",i)\n",
    "        print(action[i])\n",
    "        print(actions_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
